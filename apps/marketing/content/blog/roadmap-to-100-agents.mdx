---
title: "Our roadmap to running 100 Parallel Coding Agents"
description: "An attempt to crystallize our plans for 2026, and where we plan to focus on advancing AI"
author: Satya Patel
date: 2026-02-02
category: Product
---

Over the last year, builders have started to work in a new mode. We open fewer files, spend less time in the IDE, 
and hand more work to agents. The agents are getting smarter, and our trust in their code quality and architectural 
decisions is rising.

On our team, we can reliably run 5 to 7 agents in parallel today. We believe 100 is possible in 2026, but that scale 
won't happen just by making agents faster and better. It will require rethinking where humans spend attention and how the product mediates that attention.

# What will it take to run 100 agents in parallel

If you've attempted any of these parallel orchestration flows, you can probably guess where the bottleneck is - it's the human in the loop. Most
responsible teams still review and test agent code by hand before it's shipped to production, which means any agent code needs to go through a human.

Framing agent workflows as pipelines is a great exercise, as then the goal is clear - you can improve the total throughput
by eliminating bottlenecks where they arise. This is roughly what the pipeline looks like today:

[Show an image of user comes up with idea -> plans out a task -> hands plan to agent, loop until code is good enough, merge]

As you can see, there's a lot of places where the user is involved, and since there's only one user, agents have to do a lot of waiting before work is complete.

Agent compute, on the otherhand, is a practically-infinite resource for most teams (1000 agents active all month probably cost less than an engineer's salary)

What's interesting about this is that this means that agents can __never__ be the bottleneck. You don't care about how long it takes for one agent to complete its work, 
an agent can be running for days and you wouldn't care, as you can always just run more agents running to increase the throughput of the different agent steps.

That means most valuable thing to spend time on is the human part of the pipeline.

# Where does the time go?

Reviewing agent code takes a lot of time, and it causes an extreme amount of
whiplash. You have to juggle all of the following right now:

* Reviewing the code the agent produced
* Giving it feedback on that code
* Spinning up / tearing down devservers 
* Manually clicking around in the UI
* Planning out work for new agents

# How can we improve it

## Make agents require less human feedback
  * Can run many more code review agents before an agent comes back
  * Have the agents be more persistent (Ralph loops, etc.)
  * Have agents block interruptions to the user until an agent's work is good enough (manager/bouncer)
  * UI's morph when you think about 100 agents at once, need 
## Make it fast to review agents' work
  * Have the agent organize their work to make it easier for you to review
    * Write reports
    * Spin up dev servers for you
    * Navigate to specific pages on your site that it wants you to review
  * Have better tools for review (diff viewer, fast feedback, etc.)
  * Have quick actions like agents prepping multiple choice questions for you, have simple actions like "create PR" readily available
## Increase the amount of time you can spend working
  * Make it easy to work on your phone / on the go
  * Make the tool easy to use
  * Make it easy to start work in the cloud and pick it up when you're ready
## Have agents be more proactive
  * Have agents proactively find new work to do
  * Have agents dig into product feedback weekly
  * Have agents investigate security gaps
  etc. etc.
